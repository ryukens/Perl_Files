セントラル【central】	セン ト ラ ル	`s_eh_n t_r_ax_l
ダライラマ【Dalai Lama】	ダ ラ イ ラ マ	`d_ae `l_ey | `l_aa m_ax
レイアウト【layout】	レ イ ア ウ ト	`l_ey `aw_t
エルディーケー【LDK】	エ ル ディー ケー	`eh_l | `d_iy | `k_ey
コストパフォーマンス【cost performance】	コ ス ト パ フォー マン ス	`k_aa_s_t | p_er `f_ao_r m_ax_n_s

>>>>>>>>>>>>>>>>>>>>>>>>>>EMISION

`d_ae ダ 
`l_ey ライ
`l_aa ラ
m_ax マ

Esto permitirá mapear los fonemas ingles y los katakanas.
Listado de las palabras validadas de alineación. Con este se contará la probabilidad de que el fonema tenga aquella secuencia de katakanas.
Se  obtendra como salida una secuencia de katakanas más probable.
Con esto se genera el modelo de emisión (de lo observado a  lo oculto)
Será necesario otro modelo para obtener el nivel oculto.
Generar las probabilidades ej: dado un `d_ae cual  es la probabilidad de que sea ダ (en funcicón de las cadenas de eventos consecutivos.)
Dar un formato y subir los modelos a un simulador HMM que procesará la secuencia de estados ocultos más probables dada una secuencia de observaciones.

USAR ARREGLO ASOCIATIVO -> No usa indices numéricos, usa las palabras como indice (similar a hash). Cada unico valor es una ocurrencia. Revisar si ya existe el fonema en el hash

Formato para el diccionario (csv) de emisiones (modelo de emisiones):

Cold,Fever,0.3
Cold,Healthy,0.4
Dizzy,Fever,0.6
Dizzy,Healthy,0.1
Normal,Fever,0.1
Normal,Healthy,0.5

La suma de todos las etiquetas de estado fever y healthy debe dar 1

^(.*(?:セン|トラル|ニュー))$
^(.*(?:セン|トラル|ニュー) <\/s>)$


Conteos de los unigramas:
`n_uw	12
`s_eh_n_t	1
`s_eh_n	16
ch_ax_n	1
n_y_uw	1
s_ax_n	1
s_eh_n	2
t_r_ax_l	5
コンセン	1
セン	20
トラル	5
ニュー	13
<s> 39
</s> 39

TOTAL 156
sin <s> 117

conteo de bigramas
`n_uw ニュー	12
`s_eh_n セン	16
`s_eh_n_t コンセン	1
ch_ax_n セン	1
n_y_uw ニュー	1
s_ax_n セン	1
s_eh_n セン	2
t_r_ax_l トラル	5

Calcular probabilidades en base a los conteos
Probabilidades unigramas.
Se excluye el valor del unigrama inicial (<s> en este caso). 
</s>		39/117		
<s>			39/117
`n_uw		12/117
...			...


Calcular probabilidades bigramas
(prob de セン dado <s>)
<s> セン		0.6		3/5	(hay 5 <s>)
<s> ニュー		0.4		2/5	(hay 5 <s>)
セン トラル		1		3/3
トラル </s>	1		5/5
ニュー トラル	1		2/2


>>>>>>>>>>>>>>>>>>>>>>>>>>FORMATO ARCHIVO OBSERVACIONES
Formato para el archivo (csv) de observaciones:
Normal,Cold,Dizzy
Dizzy,Cold,Normal,Dizzy

Cada fila tendrá los fonemas del inglés.

>>>>>>>>>>>>>>>>>>>>>>>>>>MATRIZ PROBABILIDAD INICIAL
Probabilidad de inicio
Formato para el archivo (csv) de las probabilidades del vector de inicio:
Healthy,0.6
Fever,0.4


>>>>>>>>>>>>>>>>>>>>>>>>>>MODELO ALINEACION


<s> ダ ライ </s>
<s> ラ マ </s>
Generar una lista con los katakanas de cada una de las palabras de manera independiente.
Con esto se generará el modelo oculto
El modelo oculto permitirá encontrar la secuencia de katakanas siguiente en función de la anterior.
Cuando se hable del iniicio de la palabra se nececsiará un caracter que indique que es el inicio de la palabra: "<s>"
Para el fin de palabra se usará "</s>"

Con ambos se hará el conteo: dado uno de los eventos, ¿cuales son los eventos que le siguen? (analogia a una maquina de estados)
Se calculará una probabilidad condicional para los eventos siguientes dado un evento anterior. (ej: cual es la prob de que luego de un ダ le siga un ライ)

En base a las reglas que tengo validar las palabras para que no ocurran casos como (Personal Computer -> pasocon) y eso extraerlas para no formar parte de diccionarios.
Clasificar en palabras validas e invalidas.
Puede darse el caso de que palabras validas sean mal clasificadas, revisarlo!

MODELOS DE BIGRAMAS
Son dos eventos (silabas). 
Realizar los conteos. 
Bigrama depende de unigrama.
Contar unigramas:
</s>	5
<s>	5
セン	3
トラル	5
ニュー	2

TOTAL 20
TOTAL SIN <s> 15

Contar bigramas (dos eventos consecutivos): 
<s> セン	3
<s> ニュー	2
セン トラル	3
トラル </s>	5
ニュー トラル	2

Calcular probabilidades en base a los conteos
Probabilidades unigramas.
Se excluye el valor del unigrama inicial (<s> en este caso). 
</s>		1/3 -> 5/15
<s>			1/3 -> 5/15
セン			1/5 -> 3/15
トラル			1/3 -> 5/15
ニュー				   2/15

Calcular probabilidades bigramas
(prob de セン dado <s>)
<s> セン		0.6		3/5	(hay 5 <s>)
<s> ニュー		0.4		2/5	(hay 5 <s>)
セン トラル		1		3/3	(hay 3 セン
トラル </s>	1		5/5	(hay 5 トラル)
ニュー トラル	1		2/2	(hay 2 ニュー)



EL MODELO OCULTO TENDRÁ UN FORMATO -> Dos sílabas de JP con probabilidad:
Formato para el diccionario (csv) de transiciones (modelo oculto):

Healthy,Healthy,0.7
Healthy,Fever,0.3
Fever,Healthy,0.4
Fever,Fever,0.6

<s>,セン,0.6
<s>,ニュー,0.4,

En el capa oculta del modelo solo existe s /s y katakanas.


>>>>>>>>>>>>>>VECTOR INICIAL
Da las probabilidades de como puede inciar una cadena  y una palabra.
Probabilidad de con que katakana se iniciaria.
De todas las  secuencias katakana de inicio de palabra se debe sacar una nueva probabilidad que será e l vector inicial.
el  resto de la paalabra se lo maneja cocnn el modelo oculto.


>>>>>>>>>>>>>>SIMPLE

# Sentence pair (1558) source length 2 target length 5 alignment score : 3.57092e-06
レ イ ト ア ト 
NULL ({ 2 3 }) `l_eyt ({ 1 }) `aw_t ({ 4 5 })

>>>>>>>>>>>>>>MULTIPLE

# Sentence pair (404) source length 5 target length 5 alignment score : 1.77802e-06
ダ ラ イ ラ マ 
NULL ({ 3 }) `d_ae ({ 1 }) `l_ey ({ 2 }) | ({ }) `l_aa ({ 4 }) m_ax ({ 5 }) 
# Sentence pair (305) source length 5 target length 7 alignment score : 3.23564e-06
コ ス ト パ フォー マン ス 
NULL ({ }) `k_aa_s_t ({ 1 2 3 }) | ({ }) p_er ({ 4 }) `f_ao_r ({ 5 }) m_ax_n_s ({ 6 7 }) 
# Sentence pair (305) source length 5 target length 7 alignment score : 3.23564e-06
コ ス ト パ フォー マン ス 
NULL ({ 2 }) `k_aa_s_t ({ 1 3 }) | ({ 5 }) p_er ({ 4 }) `f_ao_r ({ }) m_ax_n_s ({ 6 7 }) 

>>>>>>>>>>>>>>>>COMBINADO

# Sentence pair (1) source length 2 target length 4 alignment score : 0.00481252
セン ト ラ ル 
NULL ({ }) `s_eh_n ({ 1 }) t_r_ax_l ({ 2 3 4 }) 
# Sentence pair (404) source length 5 target length 5 alignment score : 1.77802e-06
ダ ラ イ ラ マ 
NULL ({ 3 }) `d_ae ({ 1 }) `l_ey ({ 2 }) | ({ }) `l_aa ({ 4 }) m_ax ({ 5 }) 
# Sentence pair (1558) source length 2 target length 5 alignment score : 3.57092e-06
レ イ ア ウ ト 
NULL ({ 2 5 }) `l_ey ({ 1 }) `aw_t ({ 3 4 }) 
# Sentence pair (1989) source length 2 target length 3 alignment score : 7.9192e-06
モー ト ル 
NULL ({ 2 }) `m_ow ({ 1 }) t_er ({ 3 }) 
# Sentence pair (1560) source length 5 target length 4 alignment score : 0.0154121
エ ル ディー ケー 
NULL ({ }) `eh_l ({ 1 2 }) | ({ }) `d_iy ({ 3 }) | ({ }) `k_ey ({ 4 }) 
# Sentence pair (305) source length 5 target length 7 alignment score : 3.23564e-06
コ ス ト パ フォー マン ス 
NULL ({ 2 }) `k_aa_s_t ({ 1 3 }) | ({ 4 }) p_er ({ }) `f_ao_r ({ 5 }) m_ax_n_s ({ 6 7 }) 

>>>>>>>>>>>>>>>>ALINEADO

# Sentence pair (404) source length 5 target length 5 alignment score : 1.77802e-06
ダ ラ イ ラ マ 
NULL ({ }) `d_ae ({ 1 3 }) `l_ey ({ 2 3 }) | ({ }) `l_aa ({ 4 }) m_ax ({ 5 }) 
# Sentence pair (1) source length 2 target length 4 alignment score : 0.00481252
セン ト ラ ル 
NULL ({ }) `s_eh_n ({ 1 }) t_r_ax_l ({ 2 3 4 }) 
# Sentence pair (2) source length 5 target length 7 alignment score : 6.25419e-05
セン ト ラ ル ヒー ティン グ 
NULL ({ }) `s_eh_n ({ 1 }) t_r_ax_l ({ 2 3 4 }) | ({ }) `hh_iy ({ 5 }) t_ax_ng ({ 6 7 }) 
# Sentence pair (297) source length 2 target length 4 alignment score : 5.07816e-05
コ ル セッ ト 
NULL ({ }) `k_ao_r ({ 1 }) s_ax_t ({ 2 3 4 }) 
# Sentence pair (298) source length 2 target length 3 alignment score : 0.00230558
コ サ イン 
NULL ({ }) `k_ow ({ 1 }) `z_iy_n ({ 2 3 }) 

>>>>>>>>>>>>>>>>ERROR ALINEACION FESTIVAL

# Sentence pair (2092) source length 3 target length 5 alignment score : 1.95933e-06
ナ イ チン ゲー ル 			(nightingale)
NULL ({ }) `n_ay ({ 1 2 }) t_ax_ng ({ }) g_ey_l ({ 3 4 5 }) 
# Sentence pair (63) source length 4 target length 8 alignment score : 4.76006e-08
カ イ ロ プ ラ ク ティッ ク 		(chiropractic)
NULL ({ 2 }) `k_ay ({ 1 }) r_ow ({ 3 }) `p_r_ae_k ({ 4 5 6 }) t_ax_k ({ 7 8 }) 

>>>>>>>>>>>>>>>>ERROR ALINEACION MANUAL

# Sentence pair (1368) source length 3 target length 6 alignment score : 7.3418e-05
イン ス ト ラ ク ター 
NULL ({ }) ih_n ({ 1 }) `s_t_r_ah_k ({ 2 3 4 5 }) t_er ({ 6 }) 
# Sentence pair (306) source length 2 target length 4 alignment score : 0.00566287
コ ス チュー ム 
NULL ({ }) k_aa ({ 1 }) `s_t_uw_m ({ 2 3 4 }) 
# Sentence pair (1558) source length 2 target length 5 alignment score : 3.57092e-06
レ イ ア ウ ト 
NULL ({ }) `l_ey ({ 1 2 }) `aw_t ({ 3 4 5 }) 

>>>>>>>>>>>>>>>>CODIFICACIÓN UTF-8

# Sentence pair (856) source length 3 target length 4 alignment score : 0.0028254
エ フ エ ム 
NULL ({ }) `eh_f ({ 1 2 }) | ({ }) `eh_m ({ 3 4 }) 

>>>>>>>>>>>>>>>>GENERACIÓN DICCIONARIOS

# Sentence pair (1) source length 2 target length 4 alignment score : 0.00481252
セン ト ラ ル 
NULL ({ }) `s_eh_n ({ 1 }) t_r_ax_l ({ 2 3 4 }) 
# Sentence pair (2) source length 5 target length 7 alignment score : 6.25419e-05
セン ト ラ ル ヒー ティン グ 
NULL ({ }) `s_eh_n ({ 1 }) t_r_ax_l ({ 2 3 4 }) | ({ }) `hh_iy ({ 5 }) t_ax_ng ({ 6 7 }) 
# Sentence pair (241) source length 3 target length 3 alignment score : 2.14907e-07
サン チ マン 
NULL ({ }) `s_eh_n ({ 1 }) t_ax ({ 2 }) m_ax_n_t ({ 3 }) 
# Sentence pair (297) source length 2 target length 4 alignment score : 5.07816e-05
コ ル セッ ト 
NULL ({ }) `k_ao_r ({ 1 2 }) s_ax_t ({ 3 4 }) 
# Sentence pair (298) source length 2 target length 3 alignment score : 0.00230558
コ サ イン 
NULL ({ }) `k_ow ({ 1 }) `z_iy_n ({ 2 3 }) 
# Sentence pair (299) source length 3 target length 5 alignment score : 0.00181788
コ ス メ ティッ ク 
NULL ({ }) k_aa_z ({ 1 2 }) `m_eh ({ 3 }) t_ax_k_s ({ 4 5 }) 
# Sentence pair (300) source length 4 target length 6 alignment score : 3.68748e-05
コ ス モ ポ リ ス 
NULL ({ }) `k_ao_z ({ 1 2 }) m_ax ({ 3 }) p_ax ({ 4 }) l_ax_s ({ 5 6 }) 
# Sentence pair (301) source length 5 target length 6 alignment score : 0.000113615
コ ス モ ポ リ タン 
NULL ({ }) `k_aa_z ({ 1 2 }) m_ax ({ 3 }) `p_aa ({ 4 }) l_ax ({ 5 }) t_ax_n ({ 6 }) 
# Sentence pair (302) source length 7 target length 9 alignment score : 5.72292e-06
コ ス モ ポ リ タ ニ ズ ム 
NULL ({ }) `k_ao_z ({ 1 2 }) m_ax ({ 3 }) `p_aa ({ 4 }) l_ax ({ 5 }) t_ax ({ 6 }) `n_ih ({ 7 }) z_ax_m ({ 8 9 }) 
# Sentence pair (303) source length 2 target length 4 alignment score : 0.00705866
コ ス モ ス 
NULL ({ }) `k_aa_z ({ 1 2 }) m_ow_s ({ 3 4 }) 
# Sentence pair (304) source length 1 target length 3 alignment score : 0.0129289
コ ス ト 
NULL ({ }) `k_aa_s_t ({ 1 2 3 }) 
# Sentence pair (305) source length 5 target length 7 alignment score : 3.23564e-06
コ ス ト パ フォー マン ス 
NULL ({ }) `k_aa_s_t ({ 1 2 3 }) | ({ }) p_er ({ 4 }) `f_ao_r ({ 5 }) m_ax_n_s ({ 6 7 }) 
# Sentence pair (306) source length 2 target length 4 alignment score : 0.00566287
コ ス チュー ム 
NULL ({ }) k_aa ({ 1 }) `s_t_uw_m ({ 2 3 4 }) 
# Sentence pair (307) source length 2 target length 3 alignment score : 0.0384434
コ テー ジ 
NULL ({ }) `k_aa ({ 1 }) t_ax_jh ({ 2 3 }) 
# Sentence pair (308) source length 2 target length 2 alignment score : 0.00420474
コッ トン 
NULL ({ }) `k_aa ({ 1 }) t_ax_n ({ 2 }) 

>>>>>>>>>>>>>>>>INDEPENDIENTE

# Sentence pair (1) source length 2 target length 4 alignment score : 0.00481252
セン ト ラ ル 
NULL ({ }) `s_eh_n ({ 1 }) t_r_ax_l ({ 2 3 4 }) 
# Sentence pair (308) source length 2 target length 2 alignment score : 0.00420474
コッ トン 
NULL ({ }) `k_aa ({ 1 }) t_ax_n ({ 2 }) 

>>>>>>>>>>>>>>>>DE EDICT2 TRAIN

# Sentence pair (1) source length 3 target length 4 alignment score : 8.03033e-05
レ イ アッ プ 
NULL ({ }) `l_ey ({ 1 }) - ({ 2 }) `ah_p ({ 3 4 }) 
# Sentence pair (2) source length 2 target length 2 alignment score : 0.0138487
フォー チュン 
NULL ({ }) `f_ao_r ({ 1 }) ch_ax_n ({ 2 }) 
# Sentence pair (3) source length 4 target length 5 alignment score : 0.000182038
フ ルー ツ ゼ リー 
NULL ({ }) `f_r_uw_t ({ 1 2 3 }) | ({ }) `jh_eh ({ 4 }) l_iy ({ 5 }) 
# Sentence pair (4) source length 5 target length 7 alignment score : 0.000105012
ビ ブ リ オ グ ラ フィー 
NULL ({ }) `b_ih ({ 1 }) b_l_iy ({ 2 3 }) `aa ({ 4 }) g_r_ax ({ 5 6 }) f_iy ({ 7 }) 
# Sentence pair (5) source length 7 target length 8 alignment score : 5.50108e-21
ナン ヨ ウ ミ ド リ ハ ゼ 
NULL ({ }) `g_r_iy_n ({ 1 2 3 }) | ({ }) `b_ah ({ 4 }) b_ax_l ({ }) | ({ 5 }) `g_ow ({ 6 7 }) b_iy ({ 8 }) 
# Sentence pair (6) source length 3 target length 4 alignment score : 3.73933e-09
ティーン エ イ ジャー 
NULL ({ 3 }) `t_iy ({ 1 }) `n_ey ({ 2 }) jh_er ({ 4 }) 
# Sentence pair (7) source length 3 target length 4 alignment score : 0.00127309
コ ヒー レン ト 
NULL ({ }) k_ow ({ 1 }) `hh_ih ({ 2 }) r_ax_n_t ({ 3 4 }) 
# Sentence pair (8) source length 3 target length 5 alignment score : 0.000418605
バ ス マ ウ ス 
NULL ({ }) `b_ah_s ({ 1 2 }) | ({ }) `m_aw_s ({ 3 4 5 }) 
# Sentence pair (9) source length 6 target length 11 alignment score : 2.66774e-21
ブ ルー アン ド イ エ ロー ク ロ ミ ス 
NULL ({ }) `l_ih_m ({ 1 }) `b_ao_z ({ 2 3 4 6 7 9 10 }) | ({ }) `d_ae_m ({ }) s_ax_l ({ 8 11 }) `f_ih_sh ({ 5 }) 
# Sentence pair (10) source length 4 target length 5 alignment score : 0.000297393
ス チー ム ヒー ター 
NULL ({ }) `s_t_iy_m ({ 1 2 3 }) | ({ }) `hh_iy ({ 4 }) t_er ({ 5 }) 
# Sentence pair (11) source length 4 target length 6 alignment score : 9.64652e-05
サ ポー ト グ ルー プ 
NULL ({ }) s_ax ({ 1 }) `p_ao_r_t ({ 2 3 }) | ({ }) `g_r_uw_p ({ 4 5 6 }) 
# Sentence pair (12) source length 3 target length 4 alignment score : 0.00592741
シ ス ジェン ダー 
NULL ({ }) s_ih_s ({ 1 2 }) `g_eh_n ({ 3 }) d_er ({ 4 }) 
# Sentence pair (3647) source length 7 target length 10 alignment score : 1.38701e-06
サー ビ ス ア ク セ ス ポ イン ト 
NULL ({ }) `s_er ({ 1 }) v_ax_s ({ 2 3 }) | ({ }) `ae_k ({ 4 5 }) `s_eh_s ({ 6 7 }) | ({ }) `p_oy_n_t ({ 8 9 10 }) 

>>>>>>>>>>>>>>>>EJERCICIO PROBABILIDADES EMISION

<s> l_ax_s リス </s>
<s> l_ax_s リス </s>
<s> l_ax_s リス </s>
<s> l_ax_s レス </s>
<s> l_ax_s リス </s>
<s> l_ax_s レス </s>
<s> l_ax_s レス </s>
<s> l_ax_s レス </s>
<s> l_ax_s レス </s>
<s> l_ax_s レス </s>
<s> l_ax_s レス </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニッ </s>
<s> `n_ih ニッ </s>
<s> `n_ih ニッ </s>
<s> `n_ih ニ </s>
<s> `n_ih ニッ </s>
<s> `n_ih ニー </s>
<s> `n_ih ニ </s>
<s> t_r_ax_l トラル </s>
<s> t_r_ax_l トラル </s>
<s> t_r_ax_l トラル </s>
<s> t_r_ax_l トラル </s>
<s> t_r_ax_l トラル </s>


>>>>>>>>>>>>>>>>PROBABILIDADES ALINEACIÓN

<s> セン トラル </s>
<s> セン トラル </s>
<s> ヒー ティング </s>
<s> コル セット </s>
<s> コ サイン </s>
<s> コス メ ティック </s>
<s> コス モ ポ リス </s>
<s> コス モ ポ リ タン </s>
<s> コス モ ポ リ タ ニ ズム </s>
<s> コス モス </s>
<s> コスト </s>
<s> コスト </s>
<s> パ フォー マンス </s>
<s> コ スチューム </s>
<s> コ テージ </s>
<s> コッ トン </s>

Distribución vector inicial.
コス 		5/16
セン 		2/16
ヒー		1/16
コル		1/16
コ		3/16
コスト		2/16
パ		1/16
コッ		1/16




PROBABILIDAD EMISION
<s>,<s>,1.000
</s>,</s>,1.000
`k_ao_r,コル,1.000

VECTOR INICIAL
En función del diccionario de transición.
Secuencia de katakanas que puede iniciar una palabra.
コス 		5/16
セン 		2/16
ヒー		1/16
コル		1/16
コ		3/16
コスト		2/16
パ		1/16
コッ		1/16

Probabilidad TRANSICIÓN
Solo existe s /s secuencias de katakanas
Deterinar secucncia katakana siguiente dada una secuencia anterior.
500 estados ocultos como mucho
Mi archivo -> probabilidades_transicion.csv

OBSERVACIONES
Se necesita un nuevo diccionario. Similar a mi archivo -> katakana-english. cocn nuevavs palabras diferentes.
Con este sse generan las secuencias fonéticas del inglés.
Se me devolverá un archihvov solo con las silabas fonéticas del inglés.
Esto será la entrada para que el simulador logre predecir los katakanas respectivos.
Las pruebas iniciales permitiran ver que tan acertadas son las predicciones.
Luego se realiza el bucle (iterativo) de mejora del modelo.

2 MATRICES DEL MODELO INICIAL
-> Matriz de probabilidades de emisión
Mapeo entre las sílabas fonéticas del inglés hacia las secuencias katakanas.
Se realiza en función de las probabilidades de emisión.

-> Matriz de probabilidades de transición
Se realiza en función de las probabilidades de transición.





VALIDACIONES
<s> s_ax_t セット </s>
Revisar si el "s" del fonema corresponde a un katakana de la secuencia que esa alineada.
Esto en función de las consonantes
Se usa con el archivo del diccionario de emision.
Separar en palabras validas e inválidas.
Validacion en función de la palabra completa o compuesta.

personal computer

`p_er~s_ax~n_ax_l | k_ax_m~`p_y_uw~t_er
パー ソ ナ ル コン ピュー タ 

`p_er 			パー		パ
s_ax			ソ		ソ
n_ax_l | 		ナル
k_ax_m			コン		コン 
`p_y_uw 		ピュー
t_er			タ


pasokon	
パソコン


animation tool
`ae~n_ax~`m_ey~sh_ax_n | `t_uw_l
ア ニ メー ション ソ フ ト

a	`ae	ア
ni	n_ax	ニ
ma	`m_ey	メー
tion	sh_ax_n	ション
tool	`t_uw_l	ソフト

Ariane Launch Vehicle	
ア リ アン ロ ケッ ト	
`eh~r_iy~`ae_n | `l_ao_n_ch | `v_iy~ih~k_ax_l	

A	`eh	ア
ri	r_iy	リ
ane	`ae_n	アン
Launch	`l_ao_n_ch	ロケット
Veh	`v_iy	
i	ih	
cle	k_ax_l	



# Sentence pair (1903) source length 4 target length 4 alignment score : 0.000222436
ミ ニ チュ ア 
NULL ({ }) `m_ih ({ 1 }) n_iy ({ 2 }) ax ({ }) `ch_uh_r ({ 3 4 }) 
# Sentence pair (2037) source length 4 target length 4 alignment score : 0.00214489
ナ ビ ゲー ター 
NULL ({ }) `n_ae ({ 1 }) v_ax ({ 2 }) `g_ey ({ 3 }) t_er ({ 4 }) 




Underflow -> cantidad de digitos en fraccion no es suficiente
Para evitar eso, se utiliza el  loggaritmo de la probabilidad
Ya no se multiplicarian los valores de las probabilidades, sino que se suman los vvalores en funcicón del logaritmo.
Los reesultados estarán por debajo del eje x (negativo) y al  llegar a 0 sería el 100% de probabilidad. Por ende, los valores van a tender hacia el 0.
trabajar con Logaritmo de base 10
Preferible hacer primero una resta de logaritmos entre los valores que se dividen porque al ahcerlo con el r esultado  inal puede que non quede nada.
10 elevado al logaritmo para obtener el valor decimal.




Observaciones con almenos 4000 similar al diccionario de entrenamiento.
Si se hubiera tenido una data más grande se hubiera divido. 70% 30% de distribución.

Diccionario EDICT2: 
iconv -f EUC-JP -t UTF-8 edict2 > 



Simulador HMM:
http://190.96.111.97/PHP-Auth/login.php


po vector inicial
A -> transicion
B -> Emision
Conjunto de observacioness




>>>>>>>>>>>>>>>>REGEX KATAKANA
Obtenido de: https://regex101.com/r/xhHFs2/1
https://en.wikipedia.org/wiki/Katakana_(Unicode_block)

Cambiar Timeout en Regex101 para que funcione

^[゠-ー;\(\)\[\]\s\w]*\s*\(.*$

(Obtener Katakanas y Fonemas de las entradas)
^[\x{30A0}-\x{30FF};\(\)\[\]\s\w]*\s*\(.*$

QUITAR <s> </s> y espacios en blanco
[<s>\/ ]

NORMAL
`s_k_ey,スカ,0.333333
アー,チェ,0.090909

LOG
`s_k_ey,スカ,-0.47712
アー,チェ,-1.041393

LOG Base 10
`s_k_ey,スカ,-0.477121
アー,チェ,-1.041393

10^(-0.477121) = 0.333333
log10 0.3333 = -0.477121

log(0.333333*0.090909) = log(0.333333) + log(0.090909)
log(0.030303) = -0.477121 + (-1.041393)
-1.518514 = -1.518514

PRUEBA
Se ejecuta un script para la conversionde rafemas a fofnemas cocn el festival. Se genera un archivo con:
palabra | separacion palabras | fonemas ingles por palabra

Los - en una palabra sí aparecerá en la sección fonética.
Los apostrofes -> 's nno genneran un apostrofe onéticoc, se elo trata como una palabra independiente.
Las comas , también se han añadido peror es sposible descartarlos. Pero si fuese necesario explicitamene la , pues sya se tiene considerada en el aparado fonético.


ENTRENAMIENTO
Con un script se generará el archivo 




Sseparacionn de katakana utilizando regex con la sustitución.
Usar solo katakanas como data

s/^(.*?)【.*/$1/gm
s/ //gm
s/(.)/$1 /gm				-> añade espacio
s/ $//gm					-> los espaciosen blanco al fifnal se elos elimina
s/ ([ァィゥェォャュョヮーッン])/$1/gm	-> une los katakanas pequeños con los katakanas anteriores


CONSULTAR
Sandra Bermeo
Nancy Naranjo
nancy.naranjo@epn.edu.ec


ANILLADOS
Estos son reevisados por otros docentes.

Seccionens de marco  teorico
- Fundamentos y teoría del trabajo 
	

CAP 1 - Introducción
	Porque se realiza el trabajo, justificarlo.
	Definir el problema.
	
CAP 2 - Marco Teórico
	->Conversion Grafemas  a fonemas (G2P) (FESTIVAL) Algoritmo CART Decision Trees (Briman 1984) Letter to sound rules automatic.
	->ALINEACION Secuencia KATAKANAS y Sílabas fonéticas del Inglés: Algoritmo expectation maximixation (GIZA++ -> Para estimar la alineacicón de cadenas) En base a conteos y proabilidad estadística.
	-> Modelos ocultos de Markov para identificar la secucncia katakana más probable a partir del inglés.

CAP 3 - Metodología Adoptada para tratar el problema. (ELABORACIÓN del modelo)
	Describir la data.
	Detalles de la metodología.
	
CAP 4 - Experimentación (EVALUACIÓN)

CAP 5 - Resultados de la parte experimental y discusión. (EVALUACIÓN)

CAP 6 - Optimización de resultados (OPTIMIZACIÓN)
	Solo se realizará luego de un resultado iniicial

CAP 7 - Conclusiones y Trabajos Futuros.


La EVALUACIÓN sólo usará la data de prueba y esta jamás será reemplazada.

Ampliación de la data de entrenamiento.







----------------------------------------
Cap 1. Introducción. Definir el problema. Justificar el porqué del trabajo planteado.

Cap 2. Marco teórico.

2.1 - Algoritmo Expectation Maximization (GIZA++) - Sirve para la alineación entre secuencias de katakanas y sílabas fonéticas del inglés.

2.2 - Grapheme to phoneme conversion = Letter to sound rules (G2P) (Festival) - CART Decision Trees (Briman 1984)

2.3 - Hidden Markov Models - 

Cap. 3 - Metodología adoptada para tratar el problema. Describir la Data. Elaboración de los modelos.

Cap 4. - Experimentación.

Cap 5. - Resultados y discusión de la parte experimental.

Evaluación (Data de prueba- 8 mil registros)

Cap. 6. Optmización de resultados

Cap. 7 Conclusiones y trabajos futuros.


----------------------------------------

DESFASADO POR 1 DESDE EL 1338

DESFASADO POR 2 DESDE 5733


Ejemplo:
Archivo 002
# Sentence pair (12251) source length 1 target length 2 alignment score : 0.133821
シャッ ト 
NULL ({ }) `sh_ah_t ({ 1 2 }) 


ANALIZAR: ¿por que se duplica? Revisar diccionario/palabras no validas para ver el ejemplo
spoon-feeding	スプーンフィーディング
*Posible que el - le haga repetir, validar esto.
crear estado oculto que represente al -


CAMBIOS
Añadir regex para cadenas que posean ~ pues eso representa la separacion entre sílabas, antes se usaba un espacio en blanco
ej:
# Sentence pair (10837) source length 3 target length 8 alignment score : 4.34569e-08
アッ プ ラ イ ト ピ ア ノ 
NULL ({ }) ax~`p_r_ay_t ({ 1 2 3 4 5 }) | ({ }) p_iy~`ae~n_ow ({ 6 7 8 }) 

REGEX OG: (`?\w*\s\(\{[\s\d]*\}\))
REGEX V1: ((\w*~?`?)*\w*\s\(\{[\s\d]*\}\))
*Se debe mejorar

ANTES
# Sentence pair (68) source length 2 target length 4 alignment score : 0.00148242
チョ コ レー ト 
NULL ({ }) `ch_ao ({ 1 }) k_l_ax_t ({ 2 3 4 }) 

AHORA
# Sentence pair (3899) source length 1 target length 4 alignment score : 0.000199077
チョ コ レー ト 
NULL ({ }) `ch_ao~k_l_ax_t ({ 1 2 3 4 }) 

Preferible reemplazar ~ pues cambia el proceso de alineación con giza, creo que lo empeora.



ERROR - MEJORAR PRIMER MÉTODO DE SILABIFICACIÓN (03-silabas.pl)
OG
	ブルーアンドイエロークロミス /(n) Limbaugh's damselfish (Chromis limbaughi)/blue-and-yellow chromis/EntL2547050/
CLEAN
	Limbaugh's damselfish	ブルーアンドイエロークロミス
FESTIVAL
	"9=>Limbaugh's damselfish=>Limbaugh's|damselfish=>`l_ih_m~`b_ao_z | `d_ae_m~s_ax_l~`f_ih_sh"
KATAKANA
	ブ ルー アン ド イ エ ロー ク ロ ミ ス
GIZA
	# Sentence pair (9) source length 3 target length 11 alignment score : 2.37221e-19
	ブ ルー アン ド イ エ ロー ク ロ ミ ス 
	NULL ({ }) `l_ih_m~`b_ao_z ({ 1 2 3 4 6 7 8 9 10 }) | ({ }) `d_ae_m~s_ax_l~`f_ih_sh ({ 5 11 }) 
*Está incorrecto el orden pues el 5 no está bien ubicado

DICCIONARIO EMISION
	<s> `l_ih_m~`b_ao_z ブルーアンドエロークロブス </s>
	<s> `d_ae_m~s_ax_l~`f_ih_sh イブブ </s>
*Debido a que el primer fonema tiene un indice 10, toma al katakana 1 y 0 en lugar del 10.
*Debido a que el segundo fonema tiene 5 y 11 como indices, se genera mal la secuencia katakana. 

VALIDACION
*1)Añadir una validación entre cantidad de katakanas de la secuencia y cantidad de reglas encontradas.
*2)En este ejemplo el primer fonema tiene 9 índices pero solo 6 reglas se cumplen. Sin embargo, se cumplen reglas en posiciones incorrectas, ej: 
	`l_ih_m~`b_ao_z -> ブルーアンドエロークロブス
	ENCONTRADO: 6 `l_ih_m~`b_ao_z
	*Según la regla 6: (if($en_syl_phoneme =~ /`?[bv]\w*/ && $sec_katakana =~ /(バ|ビ|ブ|ベ|ボ)/)) se cumple que existe "b" y "ブ" pero a simple vista se nota que están en lugares diferentes. "b" está en la mitad del fonema,  y "ブ" está al inicio de la secuencia.
	*Con esto en mente, puede darse el caso en que sí haya igual número de katakanas y de reglas (*1) con lo que se validaría la palabra, pero el orden es erróneo así que debería ser invalidada (¿como mejorar? ¿cómo saber qué elegir del fonema para validarlo con el katakana? ¿posición, problema elección?).
	

--------------------



A es amtriz cuadrada
B non lo es, son dos dimensiioens (N)

B
EMISION
-99 es el valor minimo en log
<s>,<s>,0.000000
<s>,ウオール,-99



</s>,</s>,0.000000
`w_ao_l,ウオール,0.000000

y asi con todas las demás

A
TRANSICION DENTRO DEL OMDELO OCULTO
エージ,</s>,0.000000
エージ,フェイク,-99
エージ,フェン,-99

y asi con todas las demás



dado unas observaciones, cogiera el cartesiano de las posibles transformacicones de las cadena iningles que se está usando.



--------------------

Asignatura Aprendize de Maquina

Unidad 1 - Programación en perl (todos los miércoles)
Lunes de 14 a 16
Miércoles de 14 - 17
En el enlace de siempre -> https://meet.google.com/cpb-fywp-hnh

PARTE DE PRUEBAS

en viterbi.pm se guardará un archivo para instalar y se tendrá acceso al  código de la librería.

https://metacpan.org/pod/Algorithm::Viterbi 
devolvera la cadena más probable dadas las observaciones, las siilabas de eingles será la entrada. Para cada palabra del ingles con pocasa sílabas trabajar direcamene cocn la palabra.

Entender la librería, alimentarlo en uncipon de mis archivos del mismo nombre.

observacion=> "s secuenciasilabas /s"

data de prueba 

my v# = algorin::vierbbbi >new solo se cara una vez, lo oros tres lineas de abajo se puede hacer de manera iteraiva en un for.

Es probable que palaras coras sean mal alineadas por cosas del modelo.

El bigrama depende de dos silabas y es posible que no exista la combinación. No va a ser suficiente. O puede que el modelo tenga una estimación insuficicente. Tal vez se necesite la sílaba anterior o la siguiente para que la estimación sea mucho mejor.

por un lado es bueno que una silaba del ingles tenga una secuencia katakana grande, pues se tendrá más contexo, hay menos variaciones y una secuencica más directa. Pero por otro lado es malo porque en casos de silaas pequeñas o de sílabas que no se encuenren prersenes en el modelo se estaría obteniendo una secuencia katakana errónea. 

Discusión de si es mejor un modelo por biramas o un modelo en función de las letras de las palabras. (DEFENSA) ¿Por que se eligieron sílabas en lugar de letras?. Entender porque se ha elegido.


Revisar el calculo parar obtener el valor maximo de la probabilidad, posiblemente en alguna parte del código se mantuvieron las multiplicaciones.

Probar si es factible trabajar con matriz de transicion incompleta, ver no en ufnciónn de la cantidad de datoos, sino en unción de los calculos (ver que los calculos son correctos al trabajar commpleto o incompleto) Revisar los CALCULOS.


entennder porque los valores son diferentes debido a la diferencia enre los algorimos




31-> trail	トレイル `t_r_ey_l

73-> central	セントラル `s_eh_n~t_r_ax_l
74-> philanthropy	フィランソロピー f_ih~`l_ae_n~th_r_ax~p_iy
132-> manipulation	マニピュレーション m_ax~`n_ih~p_y_ax~`l_ey~sh_ax_n

165-> encapsulation	エンカプセレーション eh_n~`k_ae_p~s_ax~`l_ey~sh_ax_n
3316-> interior decoration	インテリアデコレーション ih_n~`t_ih~r_iy~er | `d_eh~k_er~`ey~sh_ax_n

5866-> synchronizer	シンクロナイザー `s_ih_ng~k_r_ax~`n_ay~z_er
<s> シン クロ ニ ザー </s>


Prob_ini:-3.803959

Emision EDICT2
`n_ay,ニ,-0.234083
`n_ay,ナイ,-0.477121
`n_ay,イ,-1.380211
`n_ay,ニジェー,-1.380211

Transicion EDICT2
クロ,ニ,-1.753328
クロ,ナイズド,-1.929419
クロ,ナイ,-99 (código)

prob: クロ / 'ナイ' => '-103.28108'

prob: クロ / 'ニ' => -5.79137


# Sentence pair (5679) source length 5 target length 7 alignment score : 4.89463e-05
シン ク ロ ナ イ ゼー ション 
NULL ({ }) `s_ih_ng ({ 1 }) k_r_ax ({ 2 3 }) n_ax ({ 4 }) `z_ey ({ 5 6 }) sh_ax_n ({ 7 }) 
# Sentence pair (11930) source length 5 target length 6 alignment score : 8.3062e-07
ハー モ ナ イ ゼー ション 
NULL ({ }) `hh_aa_r ({ 1 }) m_ax ({ 2 }) n_ih ({ 3 }) `z_ey ({ 4 5 }) sh_ax_n ({ 6 }) 
# Sentence pair (21668) source length 3 target length 4 alignment score : 0.000222507
ナ イ ア シン 
NULL ({ }) `n_ay ({ 1 2 }) ax ({ 3 }) s_ax_n ({ 4 }) 
# Sentence pair (8793) source length 7 target length 7 alignment score : 1.08518e-06
ア メ リ カ ナ イ ズ 
NULL ({ }) ax ({ 1 }) `m_eh ({ 2 }) r_ax ({ 3 }) k_ax ({ 4 }) n_ax ({ 5 }) `z_ey ({ 6 7 }) sh_ax_n ({ }) 
# Sentence pair (11745) source length 3 target length 5 alignment score : 4.4183e-06
ナ イ チン ゲー ル 
NULL ({ }) `n_ay ({ 1 2 }) t_ih_ng ({ }) g_ey_l ({ 3 4 5 }) 
# Sentence pair (14668) source length 3 target length 5 alignment score : 0.000326589
ナ イ ト ラッ チ 
NULL ({ }) `n_ay_t ({ 1 2 3 }) | ({ }) `l_ae_ch ({ 4 5 }) 
# Sentence pair (17623) source length 2 target length 4 alignment score : 0.000109638
ス ナ イ パー 
NULL ({ }) `s_n_ay ({ 1 2 3 }) p_er ({ 4 }) 
# Sentence pair (8123) source length 2 target length 5 alignment score : 0.000560487
ジャッ ク ナ イ フ 
NULL ({ }) `jh_ae_k ({ 1 2 }) `n_ay_f ({ 3 4 5 }) 

`n_ay_d -> 2
`n_ay_z -> 3
`n_ay_l -> 3
`n_ay_s -> 7
`n_ay_n -> 9
`n_ay_f -> 21
`n_ay_t -> 52
otros -> 11
Total	108

`n_ay -> 33

141

Emision EDICT2
`n_ay,ニ,-0.234083
`n_ay,ナイ,-0.477121
`n_ay,イ,-1.380211
`n_ay,ニジェー,-1.380211

Mecanismo de generalización para ver si se puede optimizar.
Buscar una transición general.

DEBILIDAD DETECTADA tras la elección de la sílaba para el análisis. Inequidad entre lo que se 	mapea de un lado  a otro. (trabajo futuro - segmentación a nivel de letras)

Problema de esparcidad (machine learning). La cadena es muy larga como para encontrar lo deseado, la transición que necesitaría para completar la palabra. Tenemos una visión en funnción de la daa de entrenamiento y que podría no estar presente en la data de prueba.

`l_ey -> 175

Emision EDICT2
`l_ey,ラ,-0.934498
`l_ey,ライ,-2.110590
`l_ey,レー,-0.247267
`l_ey,レ,-0.712650
`l_ey,レイ,-0.964462
`l_ey,レッ,-2.110590




USAMOS UN MODELO ESTADÍSTICO

OPTIMIZACIÓN CON HASHES -> PROBAR CON LA DATA DE PRUEBA -> EXAMINAR MANERAS DE OPTIMIZACIÓN (En función del contexto)(Posiblemente se necesite conocer los otros probables caminos de una misma observación, en función de un ranking). Esto dependerá de sí llego a una optimización menor al 90%. El contexto depende de la granularidad del proceso de alineación (sílabas o letras por ejemplo.) 

Hash donde la primera key será el fonema latino. La llave interna tendrá la lista de katakanas obtenidas del diccionario, el valor será el logaritmo que está en las probabilidades.

Posiblemente se necesite conocer los estados que Viterbi utiliza para hacer los cálculos.

Usar la data de entrenamiento para realizar las pruebas con el algoritmo corregido. Comparar mi resultado de la prediccion con respecto a la secuencia katakana original para liistar  los ccasos conn errores. Analizar los tipos de errores más frecuentes que necesitaran ser mejorados en el proceso de alineación (GIZA) y validación de las reglas que ya tenía generado. Existiran grupos que ayudarán a identificar por donde mejorar el algoritmo.

Habrá casos frecuentes y raros (similar a distribución gausianna). Identificar las reglas más frecuentes que deben ser incorporadas en la validación. Se repite este proceso con las nuevas reglas actualizadas. Nunca se llegará a optimizar al 100%, almenos al 90% sí.

Luego con la data de prueba se sabrá que tan correcto hemos realizado el proceso. Buscar alternativas de transliteración para comparar con lo nuestro. Se conocerá el desempeño de dichas alternativas con nuestro método.

Explicar porqué se eligio trabajar con fonemas en lugar de otras alternativas. Tiene fallos y beneficios por igual. Es probable que exista una correspondencia/alineaciónn más específica entre el inglés y la secuencia katakana. 

Viterbi se sobrecargaría del otro modo (letras) y la toma de decisión podría ser más dificil. el arbol de conbinaciones sería más grande. 

Entropía.


(DOCUMENTACIÓN/TRABAJO FUTURO)Otro ejemplo de segmentación es usando a la observacion no como el fonema completo, sino en función de los caracteres individuales. Disminnuir la cantidad de caracteres para la alineación inicial.

d2i deep
prob 2.6 se puede indicar y justiicar rporque el porcentaje sería bajo o lo esperado.
https://d2l.ai/chapter_preliminaries/probability.html


`k_aa_t,クワット,-0.477121
`k_aa_t,コット,-0.176091
`l_iy_k,リーク,-0.301030
`l_iy_k,ポワロー,-0.602060
`l_iy_k,ル,-0.602060
`k_ay_t,カイト,0.000000
`f_r_eh_sh,フレッシュ,0.000000
`s_m_ih_th,スミス,0.000000
`f_ih_p_s,フィップス,0.000000
`n_ey_d,ネード,-0.367977
`n_ey_d,ナーデ,-0.845098
`n_ey_d,ナード,-0.544068
`n_ey_d,ネ,-0.845098
sh_ax_s_t,シスト,0.000000
`s_k_r_ae_m,スクラム,-0.301030
`s_k_r_ae_m,スクラン,-0.301030
`n_iy_d,ニード,0.000000
`ao_r,オレ,-1.672098
`ao_r,オア,-1.194977
`ao_r,オー,-0.240734
`ao_r,オール,-1.672098
`ao_r,オル,-0.496007




